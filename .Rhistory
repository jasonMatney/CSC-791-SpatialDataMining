install.packages("VBmix", type="source")
##############################################################
# CSC 591
# Clustering Example Code
# Raju Vatsavai
##############################################################
rm(list=ls(all=T))
library(mclust)
library(lattice)
library(MASS)
library(car)
library(utils)          # for read/write csv files
library(flexclust)      # for kcca
# read the data
# Change this to correct path
# setwd("C:\\Users\\jamatney\\Documents\\CSC791\\homework\\hw2")
d = read.table(file = "data/ds1-with-3classes.csv", header=T, sep=",")
# get field names
names (d)
# remove unnessary fields
#
du = d[,-c(1,4)]
summary(du)
# plot the data (set margins)
x1 = min(du[,1]) - 10
x2 = max(du[,1]) + 10
y1 = min(du[,2]) - 10
y2 = max(du[,2]) + 10
plot(du, main = "Data Distributions", xlim=c(x1,x2), ylim=c(y1,y2), pch=c(19), sub="2D Data")
nc = 3
d = read.table(file = "data/ds1-with-3classes.csv", header=T, sep=",")
library(SHINYstan)
launch_shinystan_demo()
??bsMOdal
??bsModal
devtools::install_github("ebailey78/shinyBS", ref = "shinyBS3")
11*40*4*.8
1400-1000
400/4
install.packages("spatialEco")
library(spatialEco)
x <- seq(-3, 3, length=200)
y <- cbind(n=dnorm(x), t=dt(x, df=10))
matplot(x, y, type='l')
x
y
dnorm
?dnorm
dnorm(x)
dnorm(x)
dnorm(x)
dnorm(x)
y
?matplot
matplot(x, y, type='l')
kl.divergence(y)
kl.divergence(y[,1:2])[3:3]
require(sp)
require(rgdal)
require(raster)
require(randomForest)
# CREATE LIST OF RASTERS
rlist=list.files(getwd(), pattern="img$", full.names=TRUE)
install.packages("randomForest")
require(randomForest)
# CREATE LIST OF RASTERS
rlist=list.files(getwd(), pattern="img$", full.names=TRUE)
rlist
xvars <- stack(rlist)
getwd()
rm(list=ls())
set.seed(0)
library(caret)
library(klaR)
library(rgdal)
library(raster)
library(rasclass)
#
# Satellite image is shown below with ground-truth data.
# There are 5 classes (buildings, roads, grass, trees, and water).
# Training file contains image coordinates for each ground-truth location on this map.
# You can extract data (3x3 or 5x5 window) centered on each point.
#
# Answer to your question lies in the image shown in the Appendix.
# Image classification consists of the following steps:
#
# 1) select few sample locations (only x,y coordinate)
#    (highlighted by red color points on the image)
#
# 2) assign labels to these points
#
#
# 4) use training data
#    (that is, extract RGB values from the
#     image for each location; this could be
#     single value or 3x3 window -- to increase sample size) to build the "model"
#
# 5) use test data to evaluate the "model"
#
# 6) Finally, use the "model" to predict labels for every pixel in the image.
#
# Also, note these are image coordinates
# (not spatial or projection coordinates),
# so it would be easy for every one,
# otherwise you have to deal with projections.
#
# Load satellite image
ilk <- raster("hw3-gt-data\\ilk-3b-1024.tif")
train <- read.csv("hw3-gt-data\\ilk-tr-xy.txt", header=FALSE, sep=",")
# Label ground truth data
test <- read.csv("hw3-gt-data\\ilk-te-xy.txt", header=FALSE, sep=",")
colnames(train) <- c("id","x","y","label")
# Load ground truth (training / test data)
# 3) divide this data (sample locations) into training and test data.
#   (different symbols represents different classes -- see the legend)
colnames(test) <- c("id","x","y","label")
# ilk <- brick(ilk)
plot(ilk)
ilk <- raster("hw3-gt-data\\ilk-3b-1024.tif")
get.wd()
getwd()
setwd("C:/Users/jamatney/Documents/GitHub/CSC-791-SpatialDataMining")
# Load satellite image
ilk <- raster("hw3-gt-data\\ilk-3b-1024.tif")
# Load ground truth (training / test data)
train <- read.csv("hw3-gt-data\\ilk-tr-xy.txt", header=FALSE, sep=",")
test <- read.csv("hw3-gt-data\\ilk-te-xy.txt", header=FALSE, sep=",")
# Label ground truth data
colnames(train) <- c("id","x","y","label")
colnames(test) <- c("id","x","y","label")
# ilk <- brick(ilk)
plot(ilk)
spplot(ilk)
getwd()
crs(ilk)
plot(ilk)
r <- raster()
r
bb <- extent(-10, 10, -20, 20)
bb
extent(r) <- bb
r <- setExtent(r, bb, keepres=TRUE)
r
extent(ilk)
395554 - 394530
4620006
- 4618982
4620006 - 4618982
bb <- extent(0, 1024, 0 1024)
bb <- extent(0, 1024, 0, 1024)
r <- setExtent(ilk, bb, keepres=TRUE)
plot(r)
spplot(r)
bb <- extent(0, 1024, 0, 1024)
# set new extent
bb <- extent(0, 1024, 0, 1024)
r <- setExtent(r, bb, keepres=TRUE)
##########################################################
##########################################################
# factorize labels
# Naive Bayes
# This has nothing to do with the raster what am I doing #
train[,4] <- factor(train[,4])
test[,4] <- factor(test[,4])
#   Do classification with at least one classifier from Naive Bayes and SVM ##
rm(list=ls())
set.seed(0)
library(caret)
library(klaR)
library(rgdal)
library(raster)
library(rasclass)
#
# Satellite image is shown below with ground-truth data.
# There are 5 classes (buildings, roads, grass, trees, and water).
# Training file contains image coordinates for each ground-truth location on this map.
# You can extract data (3x3 or 5x5 window) centered on each point.
#
# Image classification consists of the following steps:
# 1) select few sample locations (only x,y coordinate)
#
#
#
# 2) assign labels to these points
# 3) divide this data (sample locations) into training and test data.
# 4) use training data
#
#    (highlighted by red color points on the image)
# Answer to your question lies in the image shown in the Appendix.
#   (different symbols represents different classes -- see the legend)
#    (that is, extract RGB values from the
#     image for each location; this could be
#
#
#
# (not spatial or projection coordinates),
# 5) use test data to evaluate the "model"
# Also, note these are image coordinates
# 6) Finally, use the "model" to predict labels for every pixel in the image.
#     single value or 3x3 window -- to increase sample size) to build the "model"
# so it would be easy for every one,
# otherwise you have to deal with projections.
#
# set working directory
setwd("C:/Users/jamatney/Documents/GitHub/CSC-791-SpatialDataMining")
# Load satellite image
ilk <- raster("hw3-gt-data\\ilk-3b-1024.tif")
# Load ground truth (training / test data)
train <- read.csv("hw3-gt-data\\ilk-tr-xy.txt", header=FALSE, sep=",")
test <- read.csv("hw3-gt-data\\ilk-te-xy.txt", header=FALSE, sep=",")
# Label ground truth data
colnames(train) <- c("id","x","y","label")
colnames(test) <- c("id","x","y","label")
# ilk <- brick(ilk)
plot(ilk)
extent(ilk)
# set new extent
bb <- extent(0, 1024, 0, 1024)
r <- setExtent(r, bb, keepres=TRUE)
r <- raster()
bb <- extent(0, 1024, 0, 1024)
extent(r) <- bb
r <- setExtent(r, bb, keepres=TRUE)
spplot(r)
#   Do classification with at least one classifier from Naive Bayes and SVM ##
rm(list=ls())
set.seed(0)
library(caret)
library(klaR)
library(rgdal)
library(raster)
library(rasclass)
#
# Satellite image is shown below with ground-truth data.
# There are 5 classes (buildings, roads, grass, trees, and water).
# Training file contains image coordinates for each ground-truth location on this map.
#
# Image classification consists of the following steps:
# 1) select few sample locations (only x,y coordinate)
#
#   (different symbols represents different classes -- see the legend)
#
# Answer to your question lies in the image shown in the Appendix.
#    (highlighted by red color points on the image)
# 3) divide this data (sample locations) into training and test data.
#
# You can extract data (3x3 or 5x5 window) centered on each point.
# 2) assign labels to these points
#
# 4) use training data
#    (that is, extract RGB values from the
#     single value or 3x3 window -- to increase sample size) to build the "model"
#
# 6) Finally, use the "model" to predict labels for every pixel in the image.
# 5) use test data to evaluate the "model"
#
#     image for each location; this could be
#
# Also, note these are image coordinates
# (not spatial or projection coordinates),
# so it would be easy for every one,
# otherwise you have to deal with projections.
#
# set working directory
setwd("C:/Users/jamatney/Documents/GitHub/CSC-791-SpatialDataMining")
# Load satellite image
ilk <- raster("hw3-gt-data\\ilk-3b-1024.tif")
# Load ground truth (training / test data)
train <- read.csv("hw3-gt-data\\ilk-tr-xy.txt", header=FALSE, sep=",")
test <- read.csv("hw3-gt-data\\ilk-te-xy.txt", header=FALSE, sep=",")
# Label ground truth data
colnames(train) <- c("id","x","y","label")
colnames(test) <- c("id","x","y","label")
# ilk <- brick(ilk)
plot(ilk)
spplot(ilk)
extent(ilk)
# set new extent
r <- raster()
bb <- extent(0, 1024, 0, 1024)
extent(r) <- bb
r <- setExtent(ilk, bb, keepres=TRUE)
plot(r)
plot(train[["x"]])
plot(train[["x"]], train[["x"]])
plot(train[["x"]], train[["y"]])
plot(r)
plot(train[["x"]], train[["y"]], add=TRUE, col='red', pch=3, cex=2)
plot(test[["x"]], test[["y"]], add=TRUE, col='blue', pch=13, cex=2)
plot(r)
points(train[["x"]], train[["y"]], add=TRUE, col='red', pch=3, cex=2)
plot(r)
points(train[["x"]], train[["y"]], col='red', pch=3, cex=2)
plotRGB(r)
plotRGB(r,3,2,1)
r <- brick(r)
plotRGB(r,3,2,1)
points(train[["x"]], train[["y"]], col='red', pch=3, cex=2)
points(train[["x"]], train[["y"]], col='red', pch=30, cex=2)
points(train[["x"]], train[["y"]], col='red', pch=20, cex=2)
plotRGB(r,3,2,1)
points(train[["x"]], train[["y"]], col='red', pch=20, cex=2)
points(test[["x"]], test[["y"]], col='blue', pch=13, cex=2)
points(test[["x"]], test[["y"]], col='blue', pch=5, cex=2)
points(test[["x"]], test[["y"]], col='blue', pch=12, cex=2)
plotRGB(r,3,2,1)
points(train[["x"]], train[["y"]], col='red', pch=20, cex=2)
points(test[["x"]], test[["y"]], col='blue', pch=12, cex=2)
points(train[["x"]], train[["y"]], col='red', pch=20, cex=0.75)
plotRGB(r,3,2,1)
# add some points
points(train[["x"]], train[["y"]], col='red', pch=20, cex=0.75)
plotRGB(r,3,2,1)
# add some points
points(train[["x"]], train[["y"]], col='red', pch=20)
points(test[["x"]], test[["y"]], col='blue', pch=12)
install.packages("tiff")
library(tif)
library(tiff)
ilk <- readTIFF("hw3-gt-data\\ilk-3b-1024.tif")
plot(ilk)
2 + 4
